{
    "name": "root",
    "gauges": {
        "MoveToGoal.Policy.Entropy.mean": {
            "value": 1.394303560256958,
            "min": 1.394303560256958,
            "max": 1.4239497184753418,
            "count": 10
        },
        "MoveToGoal.Policy.Entropy.sum": {
            "value": 69804.4140625,
            "min": 69602.6015625,
            "max": 71630.3671875,
            "count": 10
        },
        "MoveToGoal.Environment.EpisodeLength.mean": {
            "value": 742.4347826086956,
            "min": 7.684091698506426,
            "max": 742.4347826086956,
            "count": 10
        },
        "MoveToGoal.Environment.EpisodeLength.sum": {
            "value": 51228.0,
            "min": 44245.0,
            "max": 52008.0,
            "count": 10
        },
        "MoveToGoal.Step.mean": {
            "value": 499940.0,
            "min": 49982.0,
            "max": 499940.0,
            "count": 10
        },
        "MoveToGoal.Step.sum": {
            "value": 499940.0,
            "min": 49982.0,
            "max": 499940.0,
            "count": 10
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.06763435900211334,
            "min": -0.5689943432807922,
            "max": 0.44970837235450745,
            "count": 10
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.sum": {
            "value": -54.91910171508789,
            "min": -615.65185546875,
            "max": 2592.119140625,
            "count": 10
        },
        "MoveToGoal.Environment.CumulativeReward.mean": {
            "value": -0.3333333333333333,
            "min": -1.0,
            "max": -0.3333333333333333,
            "count": 10
        },
        "MoveToGoal.Environment.CumulativeReward.sum": {
            "value": -23.0,
            "min": -5757.0,
            "max": -23.0,
            "count": 10
        },
        "MoveToGoal.Policy.ExtrinsicReward.mean": {
            "value": -0.3333333333333333,
            "min": -1.0,
            "max": -0.3333333333333333,
            "count": 10
        },
        "MoveToGoal.Policy.ExtrinsicReward.sum": {
            "value": -23.0,
            "min": -5757.0,
            "max": -23.0,
            "count": 10
        },
        "MoveToGoal.Losses.PolicyLoss.mean": {
            "value": 0.02109373847876365,
            "min": 0.02109373847876365,
            "max": 0.02694146556314081,
            "count": 10
        },
        "MoveToGoal.Losses.PolicyLoss.sum": {
            "value": 0.10546869239381826,
            "min": 0.08532626714246969,
            "max": 0.12510740624275057,
            "count": 10
        },
        "MoveToGoal.Losses.ValueLoss.mean": {
            "value": 0.004560923886795838,
            "min": 0.004560923886795838,
            "max": 0.42230056107897934,
            "count": 10
        },
        "MoveToGoal.Losses.ValueLoss.sum": {
            "value": 0.02280461943397919,
            "min": 0.020259764183235045,
            "max": 1.6892022443159174,
            "count": 10
        },
        "MoveToGoal.Policy.LearningRate.mean": {
            "value": 1.646697451104e-05,
            "min": 1.646697451104e-05,
            "max": 0.00028463205512264993,
            "count": 10
        },
        "MoveToGoal.Policy.LearningRate.sum": {
            "value": 8.23348725552e-05,
            "min": 8.23348725552e-05,
            "max": 0.0012846540717820001,
            "count": 10
        },
        "MoveToGoal.Policy.Epsilon.mean": {
            "value": 0.10548896,
            "min": 0.10548896,
            "max": 0.19487734999999998,
            "count": 10
        },
        "MoveToGoal.Policy.Epsilon.sum": {
            "value": 0.5274448,
            "min": 0.4999808000000001,
            "max": 0.9282180000000001,
            "count": 10
        },
        "MoveToGoal.Policy.Beta.mean": {
            "value": 0.00028389910400000007,
            "min": 0.00028389910400000007,
            "max": 0.004744379765,
            "count": 10
        },
        "MoveToGoal.Policy.Beta.sum": {
            "value": 0.0014194955200000003,
            "min": 0.0014194955200000003,
            "max": 0.021418078199999996,
            "count": 10
        },
        "MoveToGoal.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "MoveToGoal.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1684966788",
        "python_version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\andre\\OneDrive\\Documents\\RL-Unity-Project\\venv\\Scripts\\mlagents-learn --run-id=test17",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cu110",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1684967169"
    },
    "total": 381.0530215,
    "count": 1,
    "self": 0.006271900000058395,
    "children": {
        "run_training.setup": {
            "total": 0.03270329999999988,
            "count": 1,
            "self": 0.03270329999999988
        },
        "TrainerController.start_learning": {
            "total": 381.01404629999996,
            "count": 1,
            "self": 0.6087051999984396,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.817864999999999,
                    "count": 1,
                    "self": 6.817864999999999
                },
                "TrainerController.advance": {
                    "total": 373.55860660000155,
                    "count": 35859,
                    "self": 0.5583613999942258,
                    "children": {
                        "env_step": {
                            "total": 253.0710336000029,
                            "count": 35859,
                            "self": 178.26492160000225,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 74.4166243000048,
                                    "count": 35859,
                                    "self": 1.7242675000055243,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 72.69235679999927,
                                            "count": 31284,
                                            "self": 32.262499700003474,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 40.4298570999958,
                                                    "count": 31284,
                                                    "self": 40.4298570999958
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.38948769999582034,
                                    "count": 35859,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 374.8914150999963,
                                            "count": 35859,
                                            "is_parallel": true,
                                            "self": 234.42364669999589,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00031850000000055445,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00011470000000013414,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0002038000000004203,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0002038000000004203
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 140.46744990000045,
                                                    "count": 35859,
                                                    "is_parallel": true,
                                                    "self": 3.928967300006292,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 8.384539299998846,
                                                            "count": 35859,
                                                            "is_parallel": true,
                                                            "self": 8.384539299998846
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 119.06363589999835,
                                                            "count": 35859,
                                                            "is_parallel": true,
                                                            "self": 119.06363589999835
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 9.090307399996945,
                                                            "count": 35859,
                                                            "is_parallel": true,
                                                            "self": 3.949064099997372,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 5.141243299999573,
                                                                    "count": 71718,
                                                                    "is_parallel": true,
                                                                    "self": 5.141243299999573
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 119.92921160000442,
                            "count": 35859,
                            "self": 0.8319077000003574,
                            "children": {
                                "process_trajectory": {
                                    "total": 51.73578620000404,
                                    "count": 35859,
                                    "self": 51.68319050000406,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.05259569999998348,
                                            "count": 1,
                                            "self": 0.05259569999998348
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 67.36151770000002,
                                    "count": 48,
                                    "self": 47.94766920000075,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 19.41384849999927,
                                            "count": 1440,
                                            "self": 19.41384849999927
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.000000212225132e-07,
                    "count": 1,
                    "self": 6.000000212225132e-07
                },
                "TrainerController._save_models": {
                    "total": 0.02886889999996356,
                    "count": 1,
                    "self": 0.001531999999940581,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.02733690000002298,
                            "count": 1,
                            "self": 0.02733690000002298
                        }
                    }
                }
            }
        }
    }
}